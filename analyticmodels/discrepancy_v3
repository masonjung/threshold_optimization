import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import itertools
from scipy.stats import mannwhitneyu

class FairThresholdAnalysis:
    def __init__(self, filepath, feature_columns, probability_columns, quantile_range=(0.25, 0.75)):
        # Load dataset from the given file path
        self.df = pd.read_csv(filepath)
        self.feature_columns = feature_columns
        self.probability_columns = probability_columns
        self.quantile_range = quantile_range
        self.results = []

    def calculate_discrepancies(self):
        # Iterate through each probability column
        for prob_col in self.probability_columns:
            # Filter dataset to focus on the "gray zone" (probability values between quantile_range)
            lower_quantile, upper_quantile = self.quantile_range
            df_filtered = self.df[
                (self.df[prob_col] >= lower_quantile) & 
                (self.df[prob_col] <= upper_quantile)
            ]

            # Group by the feature columns
            grouped = df_filtered.groupby(self.feature_columns)
            group_keys = list(grouped.groups.keys())

            # Iterate over all unique pairs of group keys
            for val1, val2 in itertools.combinations(group_keys, 2):
                group1 = grouped.get_group(val1)[prob_col]
                group2 = grouped.get_group(val2)[prob_col]

                # Ensure groups have sufficient data
                if len(group1) < 5 or len(group2) < 5:
                    continue

                # Perform the Mann-Whitney U test
                stat, p_value = mannwhitneyu(group1, group2, alternative='two-sided')

                # Calculate the median values
                group1_median = group1.median()
                group2_median = group2.median()
                diff = abs(group1_median - group2_median)

                # Store the results if p-value < 0.05
                if p_value < 0.05:
                    self.results.append({
                        'probability_column': prob_col,
                        'combination': (val1, val2),
                        'median_difference': diff,
                        'p_value': p_value
                    })

        # Sort results by median difference to determine the biggest, second biggest, and lowest discrepancies
        self.results.sort(key=lambda x: x['median_difference'], reverse=True)

    def plot_discrepancy(self, result, rank):
        # Extract information from the result
        prob_col = result['probability_column']
        val1, val2 = result['combination']
        group1_info = dict(zip(self.feature_columns, val1))
        group2_info = dict(zip(self.feature_columns, val2))
        median_difference = result['median_difference']
        p_value = result['p_value']

        # Prepare data for plotting
        df_subset1 = self.df[(self.df[self.feature_columns] == val1).all(axis=1)].copy()
        df_subset2 = self.df[(self.df[self.feature_columns] == val2).all(axis=1)].copy()
        df_subset1['Subgroup'] = 'Group 1'
        df_subset2['Subgroup'] = 'Group 2'
        df_combined = pd.concat([df_subset1, df_subset2])

        # Filter the combined dataset to focus on the "gray zone" (probability values between quantile_range)
        lower_quantile, upper_quantile = self.quantile_range
        df_combined_gray_zone = df_combined[
            (df_combined[prob_col] >= lower_quantile) & 
            (df_combined[prob_col] <= upper_quantile)
        ]

        # Separate the filtered data into the two groups
        group1_data_gray_zone = df_combined_gray_zone[df_combined_gray_zone['Subgroup'] == 'Group 1'][prob_col]
        group2_data_gray_zone = df_combined_gray_zone[df_combined_gray_zone['Subgroup'] == 'Group 2'][prob_col]

        # Check if there is enough data for plotting
        if len(group1_data_gray_zone) < 5 or len(group2_data_gray_zone) < 5:
            print(f"Not enough data points for meaningful plot in {rank} discrepancy.")
            return

        # Plotting histogram and KDE (Kernel Density Estimation) to show difference in gray zone
        plt.figure(figsize=(14, 6))

        # Histogram for the gray zone comparison
        plt.subplot(1, 2, 1)
        plt.hist(group1_data_gray_zone, bins=20, alpha=0.5, label='Group 1', color='#1f77b4', density=True)
        plt.hist(group2_data_gray_zone, bins=20, alpha=0.5, label='Group 2', color='#ff7f0e', density=True)
        plt.xlabel('Probability Score (0.25 - 0.75)', fontsize=12)
        plt.ylabel('Density', fontsize=12)
        plt.title(f'{rank.capitalize()} Discrepancy - Histogram', fontsize=14)
        plt.legend()

        # KDE plot for the gray zone comparison
        plt.subplot(1, 2, 2)
        if len(group1_data_gray_zone) > 0:
            sns.kdeplot(group1_data_gray_zone, label='Group 1', color='#1f77b4', fill=True, alpha=0.5, bw_adjust=1)
        if len(group2_data_gray_zone) > 0:
            sns.kdeplot(group2_data_gray_zone, label='Group 2', color='#ff7f0e', fill=True, alpha=0.5, bw_adjust=1)
        plt.xlabel('Probability Score (0.25 - 0.75)', fontsize=12)
        plt.ylabel('Density', fontsize=12)
        plt.title(f'{rank.capitalize()} Discrepancy - KDE Plot', fontsize=14)
        plt.legend()

        plt.tight_layout()
        plt.suptitle(
            f'{rank.capitalize()} Discrepancy in {prob_col}\n'
            f'Group 1 ({group1_info}) vs Group 2 ({group2_info})\n'
            f'Median Difference: {median_difference:.2f}, p-value: {p_value:.2e}',
            fontsize=16,
            y=1.05
        )
        plt.show()

    def analyze_and_plot(self):
        # Calculate discrepancies
        self.calculate_discrepancies()

        # Plot the biggest, second biggest, and lowest discrepancies
        if len(self.results) >= 1:
            self.plot_discrepancy(self.results[0], 'biggest')
        if len(self.results) >= 2:
            self.plot_discrepancy(self.results[1], 'second biggest')
        if len(self.results) >= 1:
            self.plot_discrepancy(self.results[-1], 'lowest')


# Usage example
if __name__ == "__main__":
    filepath = r"C:\Users\minse\Desktop\Programming\FairThresholdOptimization\datasets\train_features.csv"  # Adjust the file path accordingly
    feature_columns = ['personality', 'sentiment_label', "formality_label", "length_label"]
    probability_columns = [
        'roberta_base_openai_detector_probability',
        'roberta_large_openai_detector_probability',
        'radar_probability'
    ]

    analysis = FairThresholdAnalysis(filepath, feature_columns, probability_columns, quantile_range=(0.25, 0.75))
    analysis.analyze_and_plot()
